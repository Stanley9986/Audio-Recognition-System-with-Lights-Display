# Song Recognition System with an Audio-Driven Light Display
By Stanley Yang and Sagnik Pal

## Overview
This project combines song recognition with an interactive light display to create an engaging user experience. By integrating various hardware and software components, we built a system capable of identifying songs using the audio input from Arduino’s built-in microphone and visually representing the music through an LED matrix by having it adjust the rate at which it changes the lights based on the intensity of the music . Users can interact by playing songs from their devices or singing near the microphone, while the system attempts to recognize the song and generates a corresponding light performance.

## Description of the project
For this project, we used the Shazam API, the Arduino built-in microphone, a TFT display board, a LED NeoPixel matrix, wifi module, and logic shifters. The microphone is taking in the audio input from the environment and it uses the Arduino SPI library to receive PCM data, which is then used to be converted into a .wav file to be sent to the Shazam API. The PCM data is also used to generate lights for the LED matrix, but we used the read() function call from the PDM library for this instead of the SPI library. Depending on the maximum amplitude, which is then used to set a variable called refreshInterval. The idea is that the greater the amplitude, the faster the lights will move.

The user can interact with the system by playing a song using their electronic device or even just trying to sing a song. Our system will then attempt to identify the song the user is playing or singing. However, some limitations to our system are that if the volume at which the user is playing the song is too low, our system might not be able to pick up on the audio data, especially in a very noisy environment. In addition, the LED matrix reacts to the amplitude of the sounds, so if someone plays music very loudly near the microphone, the lights in the LED matrix will constantly move at the fastest rate, so it wouldn’t give a sense that it’s reacting to the beat of the music.

## Development process 
Our initial idea for gathering the audio input data is through using the SD and PDM library so we can save large audio files that can then be sent to the Shazam API. We drafted an initial outline of how the code would look if we were to use the idea of integrating an SD card into our project. However, we realized that we don’t necessarily need a SD card and proceeded to use the Serial interface to stream the audio data to the computer, which then uses a python server listening to the serial port, and sent this data to Shazam servers for a response back to the Arduino. The TFT works using SPI, and therefore uses a clock signal for reliable data transfer at high speeds. The Adafruit ILI9431.h library was used for displaying shapes and text on the TFT display.

As for the light display, the LED matrix uses 5V while the Arduino sends out 3V signals. Therefore, we need a logic level shifter to bridge the difference in voltage between the two hardware. We used the 74AHCT125 level converter chip for this to ensure the two devices can communicate with each other. Also, we noticed the Arduino has a 5V output instead of using an additional power supply, so we just utilized that for the power supply of the LED matrix. 

As for the code of the lighting pattern, we used the PDM library as well as the Adafruit_NeoPixel. We consulted some examples in each library to get a sense of how the library function calls works. The code for the function onPDMdata() and for starting up the PDM was taken from one of those examples in the PDM library. We originally wanted to use the matrix to display the sound wave of the audio input, so when the beat is rapid or loud, the frequency and amplitude of the waves corresponds to that. However, mapping it to an 8x8 matrix proved to be challenging so instead we opted to create another lighting pattern. The current lighting pattern first initializes each column to have their own unique color and randomizes which pixel in the column to light up. Basically, each column needs two pieces of information, a row number (where the pixel should light up) and the color scheme. Then, in the loop function, column i’s info will be passed to column i + 1, where the last column’s data is discarded, but the first column now inherits the last column’s color and randomizes a row to light the pixel up. The interval between how long the lights stay up before it refreshes so the lighting scheme changes, depends on the maximum amplitude of the live audio data. However, the lights were too bright so in order to dim it down, we created a dim factor variable and multiplied the RGB values for each color by dim factor / 255. It seems to work well, although it did make the colors indigo and pink indistinguishable from each other.

## Lessons Learned 
One thing that we learned from this project from signal processing was that the RAM of the Arduino is limited and you cannot initialize an array of short ints with size 480,000. We originally wanted to record at a rate of 48 kHz, but we eventually had to give in and record at a rate of 16 kHz so we could decrease the size of our audio data. In addition, we were able to learn the functionalities of the PDM, Adafruit_NeoPixel, Adafruit ILI9431, and SPI libraries after working with it. In addition, for setting up the LED light matrix, I had to consult online resources especially since the 74AHCT125 level converter chip has no labelings or identifications that shows what each pin represents. We used the datasheet in the description of the product on Adafruit’s website to help me with this. Then, we consulted some examples of how they did the wiring using the level shifter with Raspberry Pi. We mimicked the instructions, like since D4 is where the output from our Arduino comes from, we wired it to pin 1A for the logic shifter, etc. 

The main thing we learned was the importance of unit testing and integration testing. Though, during the proof-of-concept stage, the individual components seemed to work (the TFT display, PDM microphone, lights display and the WiFi module), upon integration, there were timing issues causing slowdowns, which prompted the shift from WiFi to Serial. It is also paramount to read the documentation for these libraries - a problem with the WiFi module that we spent hours on was a one-line fix, after I read in the WiFiEspAT documentation that since the Nano Sense has a different architecture than most Arduino boards, that fix was required!

